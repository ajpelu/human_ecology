---
title: "Evaluate commons and transhumance"
author: "ajpelu"
date: "2022-08-24"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: ecology-letters.csl
---

## Research Questions:

-   RQ1: Commons and/or transhumance differences

> Aim: Explore differences between commons (higher to lower governance, *i.e.* PON, SAN and CAS) and/or transhumance treatment (short- and long-distance) for vegetation and soil parameters (*i.e.* richness, pH, ...) taking into account other potentially influential variables such us elevation and seasonal stocking rates

-   RQ2: Which variables do explain the variance of the interest-variable (*i.e.* vegetation parameters) independently of the commons?

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
opts_chunk$set(echo = TRUE,
	             cache = FALSE,
               prompt = FALSE,
               tidy = TRUE,
               comment = NA,
               message = FALSE,
               warning = FALSE,
               autodep = TRUE)
```

```{r pkg}
source(here::here("code/load_pkgs.R"))
source(here::here("code/aux_functions.R"))
```

# Explore data

-   Import data from `cleaned_data.csv`. See [`prepare_data.Rmd`](/prepare_data.Rmd) for more details.

```{r}
d <- read_csv(here::here("data/cleaned_data.csv"), show_col_types = FALSE)
```

We have the following structure of the data:

```{r data-design}
xtabs(~commons+transh, data = d)
```

# Exploration

First, let's explore how the different dependent variables vary with the covariates independently of the `commons` and `transhumance` [see @Zuuretal2010ProtocolData].

```{r plot-visreg-loop}
# Generate a vector of the dependent variable 
var_interes <- d %>% 
  dplyr::select(riqueza, shannon, fitovol_dm3, rec_total_porc, rec_vegetal_porc) %>% 
  names()

# Loop for each dependent variable 
for (v in var_interes) {

# Vector of covariables names
covariables  <- d %>%
  dplyr::select(starts_with("sr."), altitud_m) %>%
  names() 

# V interest name 
yvar <- v

# Formula 
f <- as.formula(glue::glue('{yvar} ~ {glue::glue_collapse(covariables, sep = " + ")}'))

# Adjust model 
fit <- d %>% lm(formula = f)

# Loop to generate plots
for (i in covariables) {
  p <- visreg::visreg(fit, data = d, i, gg = TRUE) + theme_bw() + theme(panel.grid = element_blank())
  name_indivual_plot <- paste(yvar, i, sep = "_")
  assign(name_indivual_plot, p)
}

# Patchwork plot (vinterest level)
# s <- purrr::map_chr(covariables, ~paste(yvar, ., sep = "_")) %>% 
#  glue::glue_collapse(sep = " | ")


# Patchwork plot (vinterest level) Merge y-axis
saux <- purrr::map_chr(covariables, ~paste(yvar, ., sep = "_"))

s <- paste0(saux[1], " | ", 
      purrr::map_chr(saux[-1], ~paste0(., " + labs(y=NULL)")) %>% 
        glue::glue_collapse(sep = " | "))

# Evaluate 
p_vinteres <- eval(rlang::parse_expr(s))


assign(paste0("plot_",yvar), p_vinteres)
} 
```

```{r plot-visreg, fig.height=12}
all_plots_code <- purrr::map_chr(var_interes, ~paste0("plot_", .)) %>% 
  glue::glue_collapse(sep = " / ")
eval(rlang::parse_expr(all_plots_code))
```

A first concern is about the potential correlation of the seasonal stocking rates. So we evaluate the Variance Inflation factors (VIF) [see @Zuuretal2009MixedEffects].

```{r evaluate-vif, results='hide'}
myvars <- d %>% dplyr::select(starts_with("sr."), altitud_m, commons, transh) %>% names() 

vif_table <- corvif(d[,myvars]) 
```

```{r viftable}
vif_table %>% kbl(
  caption = "VIF Table"
) %>% 
  kable_paper("hover", full_width = FALSE)
```

Higher VIF values indicate higher collinearity among variables. Several cut-off values have been proposed in the literature: 3, 5 or 10 [see @Zuuretal2013BeginnerGuide for a revision]. Our results shown (Table \@ref(tab:viftable)) several variables with high VIF values. So, previously to decide what variable discard to avoid collinearity, let's explore about the correlation between seasonal stocking rates.

```{r evaluate-correlation}
co <- correlation((d %>% dplyr::select(starts_with("sr."), altitud_m))) %>% as.data.frame()
  
co_test <- cor.mtest((d %>% dplyr::select(starts_with("sr."), altitud_m)), 
          conf.level = .95)

corrplot(corr = cor((d %>% dplyr::select(starts_with("sr."), altitud_m))), 
         p.mat = co_test$p, 
         method = 'ellipse',
         type = 'lower',
         insig = 'blank',
         diag = FALSE, 
         addCoef.col = 'black', 
         order = 'AOE')$corrPos -> p1

text(p1$x, p1$y, round(p1$corr, 2))
```

`sr.sum` (*i.e.* summer stocking rate) is strongly and significantly correlated with `sr.aut` and more weekly correlated with `altitud_m`. In addition, `sr.sum` shown a high VIF-value (`r vif_table[which(rownames(vif_table) == 'sr.sum'),1]`, see Table \@ref(tab:viftable)).

```{r evaluate-vif2}
myvars2 <- myvars[-match("sr.sum", myvars)]
vif_table2 <- corvif(d[,myvars2]) 
```

Now, all VIF values are below 5.

# Modelize

-   We want to evaluate differences between commons and/or transhumance for the variables of interest ($y$, *i.e.* richness) considering also others variables (seasonal stocking rates, elevation. The general form of the model will be $$Y_{ij} = \alpha + \beta_1 \cdot elevation_{i} + \beta_2 \cdot sr.win_i + \beta_3 \cdot sr.spr_i + \\ \beta_4 \cdot sr.aut_i + \beta_5 \cdot transh_i + \beta_5\cdot commons + \epsilon_i$$

-   Our first approach will be a GLM/LM depend on the error structure.

-   Mixed model?

    -   Do we want to find for differences between level of the factor?
    -   Are the levels under study the only levels of interest (*i.e.* short-distance *vs* long-distance) or could be considered a random sample of a population of levels?

Considering the answers to that questions, we should decided to include a factor as fixed or random. `transh` variable is considered as fixed factor. Several authors [*e.g.* @Zuuretal2007AnalysingEcological] stated that factor with small numbers of levels (there is a 'rule' of \< 5 levels) must be considered as fixed to avoid problems [@Zuuretal2007AnalysingEcological] but see @Oberprilleretal2022FixedRandom.

-   The plot (`quadrat`) and the area (`cod_parcela`) should be considered as random part since we have a nested design: `+ (1|area/plot)`

## Richness

### Model

1.  Generate a linear model with all covariables as fixed part (*nota bene*: we don't include here the interaction among covariables to simplify the model. Let's do it later)

```{r model}
full_covariates <- glue::glue_collapse(myvars2, sep = "+")

yvar <- "riqueza"
f <- reformulate(full_covariates, response = yvar)

# formula for lmer4 
random_part <- "(1 | parcela/quadrat)"
covariates_lmer <- glue::glue_collapse(c(myvars2, random_part), sep = " + ")
f_lmer <- reformulate(covariates_lmer, response = yvar)

m <- lm(f, data = d)
```

Explore the model

```{r checkmodel}
check_model(m)
```

```{r checkmodel-dharma}
simulated_resid <- DHARMa::simulateResiduals(m, n = 1000)
plot(simulated_resid)
```

There are no problems at first glance, but the richness data would fit better with Poisson distribution

2.  Fit the model with GLS

```{r compare-commons-9}
m_gls <- gls(f, data = d, method = 'REML')
```

3.  Fit the mixed model

```{r compare-commons-10}
m_lme <- lme(f, random = ~ 1 | parcela/quadrat, method = 'REML', data = d)
```

4.  Compare the model

```{r compare-commons-11}
anova(m_gls, m_lme)
```

The likelihood ratio test indicates that the mixed model is not considerably better. Anyway for design we include `parcela / quadrat` as random part.

5.  Check residuals

```{r compare-commons-12}
# E <- resid(m_lme, type="normalized")
# FI <- fitted(m_lme)
# 
# boxplot(E ~ commons, data = d)
# boxplot(E ~ transh, data = d)
# plot(y=E, x=d$sr.win)
# plot(y=E, x=d$sr.aut)
# plot(y=E, x=d$sr.spr)
# plot(y=E, x=d$altitud_m)
```

### Some notes (before continue)

1.  I'm not sure that the RQ1 (Research question 1) and RQ2 should be separated, because I think they are the same model. The only difference would be how we interpreted the effects of several variables. Let have the following model: $$Richness \sim elevation + sr.spr + \ldots + pH + \ldots + transh + commons$$

If we want to explore how the different covariates (*i.e.* `sr.spr`, `estiercol`, `pH`, etc) affect to plant richness independently of the commons, we would explore how is the average response of richness to the covariate of interest (*e.g.* `pH`), and then see how that relationship varies for each of the commons. In addition, if we don't consider the commons in the model (as proposed in RQ2) we could omit potential interaction between the commons and the covariate.

For instance, look at the following plot:

```{r compare-commons-13, fig.height=9}
covs <- c("sr.win", "sr.spr", "sr.sum","sr.aut","altitud_m","cic","fosforo","mo","ph", "potasio","nitrogeno","carbono")      

d %>% dplyr::select(one_of(covs), riqueza, commons) %>% 
  pivot_longer(-c(riqueza, commons)) %>% 
  ggplot(aes(x = value, y = riqueza)) +
  geom_point(colour = "gray") + 
  geom_smooth(method = "lm", se = FALSE, colour = "black") + 
  geom_smooth(aes(group = commons, colour = commons), method = "lm", se = FALSE) +
  theme_bw() +
  theme(panel.grid = element_blank(), 
        legend.position = "bottom") + 
  facet_wrap(~name, scales = "free_x") 
  
```

2.  Another question to consider is the number of covariates. The ratio observations/covariates should be as higher as we can. Several authors stated a minimum of 15 to 25 observations per variable. So in our RQ2, there are a lot of covariates.

So, I would propose to the following approach:

1.  To perform a potential covariates selection based on: *a)* our scientific interest, but *b)* also consider to applied any reduction techniques (clustering, PCA, etc.). for instance, the covariates *commons* and *transh* must be included (they are part of the research questions that we want to know).

2.  Then, to init the modelization process with those potential variables, and then to perform the model's selection with the better covariates (most parsimonious model).

## Variables Selection

-   In a first way, we would explore the correlation between all the potential covariables

```{r}
co_all <- correlation((d %>% dplyr::select(one_of(covs)))) %>% as.data.frame()
  
co_test <- cor.mtest((d %>% dplyr::select(one_of(covs))), 
          conf.level = .95)

corrplot(corr = cor((d %>% dplyr::select(one_of(covs)))), 
         p.mat = co_test$p, 
         method = 'ellipse',
         type = 'lower',
         insig = 'blank',
         diag = FALSE, 
         addCoef.col = 'black', 
         order = 'AOE')$corrPos -> p1

text(p1$x, p1$y, round(p1$corr, 2))
```

-   Then we applied and hierarchical clustering

```{r}
aux_d <- d |> dplyr::select(one_of(covs))

covariates_corr <- cor(aux_d)
dfdis <- dist(covariates_corr, method = "euclidean")

h <- hcut(dfdis, k = 5, isdiss = TRUE)

h |> 
  fviz_dend(., rect = TRUE, horiz = TRUE, lwd = 0.5, cex = .5)
```

Based on the results, we performed a variable selection using an exhaustive search, *i.e.* checking every possible models of a maximum subsets of 12 variables. For each subset the algorithm select the best predictors. Then for a subset of 2 variables, the algorithm select the best model of two variables.

```{r}
d_vs <- d |> 
  dplyr::select(
  riqueza, 
  one_of(covs)
)

all_models <- summary(
  regsubsets(riqueza ~ ., data = d_vs, nvmax = 20, 
             force.in = "sr.aut"))


all_models$which |> 
  as.data.frame() |> 
  mutate(across(.fns = ~replace(., . == "TRUE", "+"))) |>
  mutate(across(.fns = ~replace(., . == "FALSE", ""))) |> 
  t() |> 
  kbl() |> kable_styling()
```

```{r, echo=FALSE}
# Optimum model with the highest r2 
optimum_var_adjr <- which.max(all_models$adjr2)

# How about AIC, BIC
# AIC = nlog (RSS/n) + 2p
regmod <- lm(riqueza ~ ., data = d_vs)
p <- length(coef(regmod))
n <- length(resid(regmod))

mod_aic = n * log(all_models$rss / n) + 2*(2:(p - 1))
optimum_var_aic <- which.min(mod_aic)
```

Which is the best subset? [^1]. Using an $R^2$ approach, the best subset of parameters is `r optimum_var_adjr`, and using an AIC criteria, the best subset of parameters is `r optimum_var_aic`. 

[^1]: For more info see [Dalpiaz (2022)](https://book.stat420.org/variable-selection-and-model-building.html#selection-procedures)

```{r}
plot(mod_aic ~ I(2:(p - 1)), ylab = "AIC", xlab = "parameters number", 
     pch = 20, col = "dodgerblue4", type = "b")
```

```{r, echo=FALSE}
selected_vars <- c("sr.spr",
                   "sr.aut",
                   "cic",
                   "fosforo",
                   "ph", 
                   "potasio",
                   "nitrogeno")
```

Using this information and expert knowledge, we will select the followings variables: 

```{r}
d |> dplyr::select(one_of(selected_vars)) |> names()
```

# References

